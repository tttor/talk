\section{Methods}
\frame{\tableofcontents[currentsection, hideothersubsections]}

\begin{frame}
\frametitle{Methods}

Deep DPG:
\begin{itemize}
  \item a model-free, off-policy actor-critic algorithm using deep function approximators
  \item can learn competitive policies for all of our tasks using low-dimensional observations
  (e.g. cartesian coordinates or joint angles) using the same hyper-parameters and network structure.
  \item In many cases, we are also able to learn good policies directly from pixels, again keeping hyperparameters and network structure constant
\end{itemize}

\end{frame}

